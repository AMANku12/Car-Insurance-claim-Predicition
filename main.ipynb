{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/AMANku12/Car-Insurance-claim-Predicition/blob/main/main.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oiQZHiSS7LzZ"
      },
      "source": [
        "###\n",
        "Car Insurance Claim Prediction\n",
        "\n",
        "### Introduction\n",
        "A full, production‑minded machine learning project that predicts:\n",
        "\n",
        "    Whether a customer will file a car insurance claim (classification)\n",
        "\n",
        "    The monetary value of the claim if it occurs (regression)\n",
        "\n",
        "Built from raw Kaggle data using scikit‑learn, XGBoost, and structured ML pipelines with rigorous preprocessing, feature engineering, cross‑validation, and hyperparameter tuning."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "sMyMwLOk7Lza"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.preprocessing import OneHotEncoder, OrdinalEncoder, StandardScaler\n",
        "from sklearn.impute import SimpleImputer, KNNImputer\n",
        "from sklearn.base import BaseEstimator, TransformerMixin\n",
        "from sklearn.compose import ColumnTransformer\n",
        "from sklearn.model_selection import train_test_split, cross_val_score, RandomizedSearchCV, GridSearchCV, KFold\n",
        "from sklearn.linear_model import LogisticRegression, LinearRegression, SGDRegressor\n",
        "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier, GradientBoostingClassifier, BaggingClassifier, RandomForestRegressor\n",
        "from sklearn.neighbors import KNeighborsClassifier, KNeighborsRegressor\n",
        "from sklearn.svm import LinearSVC, SVR\n",
        "from sklearn.tree import DecisionTreeClassifier, DecisionTreeRegressor\n",
        "from sklearn.metrics import ConfusionMatrixDisplay, f1_score, make_scorer, confusion_matrix, mean_squared_error, mean_absolute_error\n",
        "\n",
        "from statsmodels.stats.outliers_influence import variance_inflation_factor\n",
        "from statsmodels.tools.tools import add_constant\n",
        "\n",
        "from xgboost import XGBClassifier, XGBRegressor\n",
        "from catboost import CatBoostClassifier\n",
        "\n",
        "from scipy.stats import randint, uniform"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YZNOQDEV7Lzb"
      },
      "source": [
        "### 1. Basic Data Cleaning and Creating Train/Test Split\n",
        "#### 1.1 Reading in the data and inspection"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "txlp5_EH7Lzb",
        "outputId": "edc9c86e-8f47-4de6-87d8-85612a9a80ed",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 287
        }
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "FileNotFoundError",
          "evalue": "[Errno 2] No such file or directory: 'data/car_insurance_claim.csv'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-1360480855.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mraw_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'data/car_insurance_claim.csv'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36mread_csv\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, date_format, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options, dtype_backend)\u001b[0m\n\u001b[1;32m   1024\u001b[0m     \u001b[0mkwds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkwds_defaults\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1025\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1026\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1027\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1028\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    618\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    619\u001b[0m     \u001b[0;31m# Create the parser.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 620\u001b[0;31m     \u001b[0mparser\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    621\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    622\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mchunksize\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0miterator\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m   1618\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1619\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhandles\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mIOHandles\u001b[0m \u001b[0;34m|\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1620\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1621\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1622\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[0;34m(self, f, engine)\u001b[0m\n\u001b[1;32m   1878\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0;34m\"b\"\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1879\u001b[0m                     \u001b[0mmode\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;34m\"b\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1880\u001b[0;31m             self.handles = get_handle(\n\u001b[0m\u001b[1;32m   1881\u001b[0m                 \u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1882\u001b[0m                 \u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/pandas/io/common.py\u001b[0m in \u001b[0;36mget_handle\u001b[0;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[1;32m    871\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencoding\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;34m\"b\"\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    872\u001b[0m             \u001b[0;31m# Encoding\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 873\u001b[0;31m             handle = open(\n\u001b[0m\u001b[1;32m    874\u001b[0m                 \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    875\u001b[0m                 \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'data/car_insurance_claim.csv'"
          ]
        }
      ],
      "source": [
        "raw_data = pd.read_csv('data/car_insurance_claim.csv')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "astmZOES7Lzb"
      },
      "outputs": [],
      "source": [
        "pd.set_option('display.max_columns', None)\n",
        "raw_data.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PC3SkcN37Lzc"
      },
      "source": [
        "#### 1.2 Basic Data Cleaning\n",
        "We'll start by creating a copy of the data we've just read in."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hVT7q_B87Lzc"
      },
      "outputs": [],
      "source": [
        "# Create new copy of data\n",
        "data_df = raw_data.copy()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4JGr-x0f7Lzc"
      },
      "source": [
        "First we will rename the columns to make them more description so they are easier to work with."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TK4LnDg-7Lzc"
      },
      "outputs": [],
      "source": [
        "# Define updated column names\n",
        "col_names = {\n",
        "    'KIDSDRIV': 'num_young_drivers',\n",
        "    'BIRTH': 'date_of_birth',\n",
        "    'AGE': 'age',\n",
        "    'HOMEKIDS': 'num_of_children',\n",
        "    'YOJ': 'years_job_held_for',\n",
        "    'INCOME': 'income',\n",
        "    'PARENT1': 'single_parent',\n",
        "    'HOME_VAL': 'value_of_home',\n",
        "    'MSTATUS': 'married',\n",
        "    'GENDER': 'gender',\n",
        "    'EDUCATION': 'highest_education',\n",
        "    'OCCUPATION': 'occupation',\n",
        "    'TRAVTIME': 'commute_dist',\n",
        "    'CAR_USE': 'type_of_use',\n",
        "    'BLUEBOOK': 'vehicle_value',\n",
        "    'TIF': 'policy_tenure',\n",
        "    'CAR_TYPE': 'vehicle_type',\n",
        "    'RED_CAR': 'red_vehicle',\n",
        "    'OLDCLAIM': '5_year_total_claims_value',\n",
        "    'CLM_FREQ': '5_year_num_of_claims',\n",
        "    'REVOKED': 'licence_revoked',\n",
        "    'MVR_PTS': 'license_points',\n",
        "    'CLM_AMT': 'new_claim_value',\n",
        "    'CAR_AGE': 'vehicle_age',\n",
        "    'CLAIM_FLAG': 'is_claim',\n",
        "    'URBANICITY': 'address_type'\n",
        "}\n",
        "\n",
        "# Update column names\n",
        "data_df.rename(columns=col_names, inplace=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3QSvUb0E7Lzd"
      },
      "outputs": [],
      "source": [
        "data_df.info()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mvG6Xz6a7Lzd"
      },
      "source": [
        "Check for duplicated and null values"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZU3dOBa97Lzd"
      },
      "outputs": [],
      "source": [
        "# Check number of duplicate records\n",
        "data_df.duplicated().sum()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_Bjes3tZ7Lzd"
      },
      "source": [
        "We have a single duplictae, so let's proceed with dropping it."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "t81s0y5b7Lzd"
      },
      "outputs": [],
      "source": [
        "# Drop duplicates\n",
        "data_df.drop_duplicates(inplace=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OqEFSJd77Lzd"
      },
      "source": [
        "The currency based columns include values with '$' and ','. We need to remove these characters and convert the values to integers."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BQKRVukO7Lzd"
      },
      "outputs": [],
      "source": [
        "# Define currency based columns\n",
        "currency_cols = ['income', 'value_of_home', 'vehicle_value', '5_year_total_claims_value', 'new_claim_value']\n",
        "\n",
        "# Create function to remove '$' and ','\n",
        "def format_currency_cols(data, cols):\n",
        "    for col in cols:\n",
        "        data[col] = data[col].replace('[\\\\$,]', '', regex=True).astype('Int64')\n",
        "    return data\n",
        "\n",
        "data_df = format_currency_cols(data_df, currency_cols)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lzhTMh6-7Lzd"
      },
      "source": [
        "Many records across multiple features include a 'z_' prefix. This must be removed."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EdFIWVO77Lzd"
      },
      "outputs": [],
      "source": [
        "# Define columns that have prefix\n",
        "z_prefix_cols = ['married', 'gender', 'highest_education', 'occupation', 'vehicle_type', 'address_type']\n",
        "\n",
        "# Create function to remove 'z_' prefix\n",
        "def remove_prefix(data, cols):\n",
        "    for col in cols:\n",
        "        data[col] = data[col].replace('[z_]', '', regex=True)\n",
        "    return data\n",
        "\n",
        "data_df = remove_prefix(data_df, z_prefix_cols)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SXtb1KnB7Lze"
      },
      "source": [
        "At this stage we can drop unuseful features:\n",
        "* ID is just a unique identifier so is not needed\n",
        "* data_of_birth duplicates the age feature (as age infers this information) so is not needed"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "H4MXPuEy7Lze"
      },
      "outputs": [],
      "source": [
        "data_df.drop(['ID', 'date_of_birth'], axis=1, inplace=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OnLsHB1_7Lze"
      },
      "source": [
        "We can now inspect the data after cleaning."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3aI45GRF7Lze"
      },
      "outputs": [],
      "source": [
        "data_df.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tezjFtHq7Lze"
      },
      "source": [
        "#### 1.3 Create Train/Test Split\n",
        "Since no test set is provided by the authoer, we'll hold out a portion of the data as our test set.\n",
        "\n",
        "In terms of creating our test set, our best option here would be to use stratified sampling to prevent bias. We can do this by creating bins (strata) based on the 'new_claim_value' amount, as non-zero values here imply 'is_claim' is 1 (true) anyway. We can double check this before doing out stratified sampling:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sgE19xGI7Lze"
      },
      "outputs": [],
      "source": [
        "# Check there are no non-zero values for 'new_claim_value' where 'is_claim' = 1\n",
        "mask = (data_df['new_claim_value'] > 0) & (data_df['is_claim'] == 0)\n",
        "data_df[mask]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FpRh6Czm7Lze"
      },
      "source": [
        "Good, so we can see when 'new_claim_value' is greater than 0, 'is_claim' is always 1, which is what we would expect.\n",
        "\n",
        "Let's now see the distribution for claim values to help define the number and width of bins we should use:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2nAy3FJ67Lze"
      },
      "outputs": [],
      "source": [
        "# Create hisogram for new claim value\n",
        "sns.histplot(data_df['new_claim_value'], bins=10)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_egThiWE7Lze"
      },
      "source": [
        "We can see the feature is heavily skewed right. It would likely be best to use non-linearly spaced bins to capture the more extreme values with few instances."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gjZkU_eG7Lzf"
      },
      "outputs": [],
      "source": [
        "# Define bins\n",
        "bins = [0.0, 5000, 10_000, 15_000, 20_000, 25_000, 30_000, 35_000, 40_000, 45_000, 50_000, np.inf]\n",
        "# Define bin labels\n",
        "labels = np.arange(1, 12)\n",
        "\n",
        "# Apply the bins using cut\n",
        "data_df['claim_value_cat'] = pd.cut(data_df['new_claim_value'], bins = bins, labels= labels, include_lowest=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3TDZwRt07Lzf"
      },
      "source": [
        "We can now see the distribution of our new_claim_value categories by creating a barplot."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "G8kAljRF7Lzf"
      },
      "outputs": [],
      "source": [
        "sns.barplot(data_df['claim_value_cat'])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_2bKefUH7Lzf"
      },
      "source": [
        "The distribution looks ok for now, so we'll proceed with creating the split."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "u1h_sFb77Lzf"
      },
      "outputs": [],
      "source": [
        "# Create clean copy of training data\n",
        "X = data_df.copy()\n",
        "y = data_df['is_claim']\n",
        "\n",
        "# Drop the target feature\n",
        "X.drop(columns=['new_claim_value','is_claim'], inplace=True)\n",
        "\n",
        "# Create train/test split\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=X['claim_value_cat'])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VoxXPcF67Lzf"
      },
      "source": [
        "We can quickly compare the distibution of positive/negative class for 'is_claim' in the y_train and y_test classes:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XElUEyaf7Lzf"
      },
      "outputs": [],
      "source": [
        "train_ratio = round((y_train.sum()/len(y_train))*100,2)\n",
        "test_ratio = round((y_test.sum()/len(y_test)*100),2)\n",
        "\n",
        "print(f'Train positive class ratio: {train_ratio}%')\n",
        "print(f'Test positive class ratio: {test_ratio}%')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rHLxQDy27Lzg"
      },
      "source": [
        "This looks good. We now need to drop the claim_value_cat feature from our X train and test sets:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-uklL-dL7Lzg"
      },
      "outputs": [],
      "source": [
        "for set_ in (X_train, X_test):\n",
        "    set_.drop(columns=['claim_value_cat'], inplace=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3c4heHcx7Lzg"
      },
      "source": [
        "### 2. Exploratory Data Analysis (EDA)\n",
        "#### 2.1 Preparation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kuHUcUCv7Lzg"
      },
      "source": [
        "For the purpose of our EDA, we'll join X_train and y_train so we can investigate correlation."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GE1BLO8F7Lzg"
      },
      "outputs": [],
      "source": [
        "# Create a new copy of X_train for the analysis\n",
        "eda_test_data = X_train.copy()\n",
        "eda_test_data['is_claim'] = y_train"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BtwQqmDH7Lzj"
      },
      "source": [
        "For the purpose of the exploration, we will first update 'Yes/No' features to bonary so we can see how these correlate too. We'll also update gender to use binary values. 1 = male, 0 = female"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "etkdOMBh7Lzj"
      },
      "outputs": [],
      "source": [
        "# Define binary columns\n",
        "binary_cols = ['single_parent', 'married', 'gender', 'red_vehicle', 'licence_revoked']\n",
        "\n",
        "# Define map values\n",
        "mapping = {'Yes': 1,\n",
        "           'No': 0,\n",
        "           'yes': 1,\n",
        "           'no': 0,\n",
        "           'M': 1,\n",
        "           'F': 0,\n",
        "           }\n",
        "\n",
        "# Define function to binarise features\n",
        "def binarise_values(data, cols, map):\n",
        "    for col in cols:\n",
        "        data[col] = data[col].map(map)\n",
        "    return data\n",
        "\n",
        "# Call function\n",
        "eda_test_data = binarise_values(eda_test_data, binary_cols, mapping)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uQJsVDyi7Lzj"
      },
      "outputs": [],
      "source": [
        "# Check updated values\n",
        "eda_test_data.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SXReruhF7Lzj"
      },
      "source": [
        "#### 2.2 Correlation Matrix\n",
        "As there are many features, we'll create a correlation matrix from just the is_claim target feature."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XnfJrDZG7Lzj"
      },
      "outputs": [],
      "source": [
        "eda_test_data.corr(numeric_only=True).sort_values(by='is_claim',ascending=False)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mJN5QRbc7Lzj"
      },
      "source": [
        "Use Seaborn to create a single column heatmap plot, sorted by correlation value."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5av8HZQc7Lzj"
      },
      "outputs": [],
      "source": [
        "fig, ax = plt.subplots(figsize=(4, 8))\n",
        "\n",
        "corr_matrix = eda_test_data.corr(numeric_only=True).sort_values(by='is_claim',ascending=False)\n",
        "corr_matrix_no_claim = corr_matrix.drop('is_claim')\n",
        "\n",
        "sns.heatmap(corr_matrix_no_claim[['is_claim']],cmap='coolwarm', annot=True, vmax=0.25, vmin=-0.25)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AJ96H02n7Lzj"
      },
      "source": [
        "Obervations:\n",
        "\n",
        "Note, we are not assuming causation, only speculating at possible reasons for correlation.\n",
        "\n",
        "* Some of the features show much stronger positive correlation than others - these are perhaps the most expected, including:\n",
        "    * 5_year_num_of_claims: Having made claims previously would suggest they are more likely to make claims in the future\n",
        "    * license_points: Having points on your license may suggest your driving quality is poor, and make you more likely to be involved in an accident\n",
        "    * license_revoked: Having your license revoked suggests several minor or a serious driving related offense, perhaps reflecting your driving quality\n",
        "* Stronger negative correlations:\n",
        "    * Home value\n",
        "* Features with negligable correlation:\n",
        "    * Commute distance, red vehicle and gender show very weak correlations, so it may be beneficial to remove these to reduce the number of features passed to the models"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ihlgOGTI7Lzk"
      },
      "source": [
        "### 3. Data Cleaning and Preprocessing\n",
        "#### 3.1 Dropping Features\n",
        "We'll start by dropping the 'red_vehicle' feature, as this showed next to no correlation with the target variable."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MkzWK8r27Lzk"
      },
      "outputs": [],
      "source": [
        "X_train_raw = X_train.copy()\n",
        "\n",
        "cols_to_drop = [\n",
        "    'red_vehicle',\n",
        "]\n",
        "\n",
        "X_train_raw.drop(columns=cols_to_drop, axis=1, inplace=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "h-eevVHb7Lzk"
      },
      "source": [
        "#### 3.2 Handling Missing Values\n",
        "Let's inspect how many missing values there are in the test data:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3c3ZYLw-7Lzk"
      },
      "outputs": [],
      "source": [
        "# Check the number of missing values in each row\n",
        "X_train_raw.isnull().sum().sum()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iQ7OBwf67Lzk"
      },
      "outputs": [],
      "source": [
        "# Check how many missing values there are in each feature\n",
        "X_train_raw.isnull().sum()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QthZGyDE7Lzk"
      },
      "source": [
        "There is a fairly significant number of missing values. We will need to deal with these when developing the data pipeline. As there are quite a lot of missing values, and many of which are numerical, simple imputation like median or mean may be too naive. Instead, let's impute using KNN for more advanced imputation."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "34hmMc907Lzk"
      },
      "outputs": [],
      "source": [
        "# Create the imputer\n",
        "knn_imputer = KNNImputer(n_neighbors=2)\n",
        "\n",
        "# Define the numerical columns\n",
        "numerical_cols_df = X_train_raw.select_dtypes(include=['number'])\n",
        "numerical_cols = numerical_cols_df.columns.tolist()\n",
        "\n",
        "# Define the categorial columns for use later\n",
        "cat_cols_df = X_train_raw.select_dtypes(include=['object'])\n",
        "cat_cols = cat_cols_df.columns.tolist()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3KcyV8vu7Lzk"
      },
      "outputs": [],
      "source": [
        "# Define function to impute num features using KNN\n",
        "def num_knn_impute(data, cols, imputer):\n",
        "    data = data[cols]\n",
        "    data_imputed = pd.DataFrame(imputer.fit_transform(data))\n",
        "    data_imputed.columns = data.columns\n",
        "    return data_imputed\n",
        "\n",
        "# Run the function to impute numerical values with knn\n",
        "num_test_data_imputed = num_knn_impute(X_train_raw, numerical_cols, knn_imputer)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0hyi7FM87Lzk"
      },
      "source": [
        "We can now check some of the records that had missing data, and the subsequent imputations:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VG6yB_kC7Lzk"
      },
      "outputs": [],
      "source": [
        "# Get numerical cols as a df\n",
        "num_cols_df = X_train_raw[numerical_cols].reset_index(drop=True)\n",
        "# Select rows with missing values and show head\n",
        "missing_data_df = num_cols_df[num_cols_df.isna().any(axis=1)]\n",
        "missing_data_df.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wVi_bxG87Lzl"
      },
      "outputs": [],
      "source": [
        "# Show same records after imputation\n",
        "samples = missing_data_df.index.to_list()\n",
        "num_test_data_imputed.loc[samples].head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cyR0NToA7Lzl"
      },
      "source": [
        "We can see values have been imputed were we had missing values.\n",
        "\n",
        "For categorical value imputation, we'll use a simple imputer with 'most_frequent' as the strategy."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hfeTfNHi7Lzl"
      },
      "outputs": [],
      "source": [
        "# Create the imputer\n",
        "simple_imputer = SimpleImputer(strategy='most_frequent')\n",
        "\n",
        "# Define function to impute cat features using simple imputer\n",
        "def cat_simple_imputer(data, cols, imputer):\n",
        "    data = data[cols]\n",
        "    data_imputed = pd.DataFrame(imputer.fit_transform(data))\n",
        "    data_imputed.columns = data.columns\n",
        "    return data_imputed\n",
        "\n",
        "# Run the function to impute missing categorical values\n",
        "cat_test_data_imputed = cat_simple_imputer(X_train_raw, cat_cols, simple_imputer)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "11b4dJxD7Lzl"
      },
      "source": [
        "As before, we can now check before and after imputation for some rows with missing values:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5hPwx3x27Lzl"
      },
      "outputs": [],
      "source": [
        "# Get numerical cols as a df\n",
        "cat_cols_df = X_train_raw[cat_cols].reset_index(drop=True)\n",
        "# Select rows with missing values and show head\n",
        "missing_cat_data_df = cat_cols_df[num_cols_df.isna().any(axis=1)]\n",
        "missing_cat_data_df.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RYF3uNCy7Lzl"
      },
      "outputs": [],
      "source": [
        "# Show same records after imputation\n",
        "samples = missing_cat_data_df.index.to_list()\n",
        "cat_test_data_imputed.loc[samples].head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bvCAIIed7Lzl"
      },
      "source": [
        "We can now join the numerical and categorical data following imputation, to create the complete DataFrame."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bRt_u8Ij7Lzl"
      },
      "outputs": [],
      "source": [
        "# Rejoin dfs\n",
        "train_imputed_df = pd.concat([num_test_data_imputed, cat_test_data_imputed], axis=1)\n",
        "# Check head\n",
        "train_imputed_df.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FyTT5WZB7Lzl"
      },
      "source": [
        "We can now check again for missing values:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "loeR9_MG7Lzl"
      },
      "outputs": [],
      "source": [
        "train_imputed_df.isnull().sum()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hD1UaJle7Lzm"
      },
      "source": [
        "We can see we now have no missing values in any of the features."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FqX9vioC7Lzm"
      },
      "source": [
        "#### 3.4. Categorical Feature Encoding\n",
        "We now need to consider how we will encode the categorical features so that they can be used with machine learning algorithms. Let's start by looking at the number of unqiue values each categorical feature has, so we can decide the best encoding method for each."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BgFWkBK97Lzm"
      },
      "outputs": [],
      "source": [
        "cat_test_data_imputed.nunique()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CROB315o7Lzm"
      },
      "source": [
        "* Single parent has only 2 values, so we can use binary encoding for this feature.\n",
        "* Married has only 2 values, so we can use binary encoding for this feature.\n",
        "* Gender has only 2 values, so we can use binary encoding for this feature.\n",
        "* Highest education has 5 unique values, and these have a rank/order (the level of education). We can use ordinal encoding for this feature.\n",
        "* For occupation, we have 8 differnet values with no ranking or order. We can use one-hot encoding for this feature.\n",
        "* Type of use has only 2 values, so we can use binary encoding for this feature.\n",
        "* Vehicle type has 6 different values with no ranking or order. We can use one-hot encoding for this feature.\n",
        "* Red vehicle has only 2 values, so we can use binary encoding for this feature.\n",
        "* License revoked has only 2 values, so we can use binary encoding for this feature.\n",
        "* Address type has only 2 values, so again, we can use binary encoding for this feature.\n",
        "\n",
        "Since Scikit-Learn has no binary encoding option currently for independent features, we can use the ordinal encoder in this as we only have 2 unique values. We can now define which features will use which encoders:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "y2_ynp9E7Lzm"
      },
      "outputs": [],
      "source": [
        "# Define ordinal features\n",
        "cat_cols_ord = ['highest_education']\n",
        "# Define binary features\n",
        "cat_cols_bin = ['single_parent', 'married', 'gender', 'type_of_use', 'licence_revoked', 'address_type']\n",
        "# Define one-hot features\n",
        "cat_cols_one_hot = ['occupation', 'vehicle_type']"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Lm3M2TE87Lzm"
      },
      "source": [
        "We can now create the encoders for each feature type. For the education encoder we will first need to define the order/ranking of the levels of education."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yHzTiksm7Lzm"
      },
      "outputs": [],
      "source": [
        "education_rank = [['<High School', 'High School', 'Bachelors', 'Masters', 'PhD']]\n",
        "\n",
        "# Define ordinal encoder\n",
        "ord_encoder = OrdinalEncoder(categories=education_rank)\n",
        "\n",
        "# Define binary encoder\n",
        "bin_encoder = OrdinalEncoder()\n",
        "\n",
        "# Define one-host encoder\n",
        "one_hot_encoder = OneHotEncoder(handle_unknown='ignore', sparse_output=False)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IDWcEEQl7Lzm"
      },
      "source": [
        "We can now encode the values use fit_transform:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Yuk3_0Qa7Lzm"
      },
      "outputs": [],
      "source": [
        "# Encode ordinals\n",
        "ord_encoded = ord_encoder.fit_transform(cat_test_data_imputed[cat_cols_ord])\n",
        "\n",
        "# Encode binaries\n",
        "bin_encoded = bin_encoder.fit_transform(cat_test_data_imputed[cat_cols_bin])\n",
        "\n",
        "# One-hot encoding\n",
        "one_hot_encoded = one_hot_encoder.fit_transform(cat_test_data_imputed[cat_cols_one_hot])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yovyYQQb7Lzm"
      },
      "source": [
        "We can now return these values to a DataFrame to check the encoding:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AaeuQO9c7Lzm"
      },
      "outputs": [],
      "source": [
        "# Create dfs for each array\n",
        "ord_encoded_df = pd.DataFrame(ord_encoded)\n",
        "ord_encoded_df.columns = cat_cols_ord\n",
        "\n",
        "bin_encoded_df = pd.DataFrame(bin_encoded)\n",
        "bin_encoded_df.columns = cat_cols_bin\n",
        "\n",
        "one_hot_encoded_df = pd.DataFrame(one_hot_encoded)\n",
        "one_hot_encoded_df.columns = one_hot_encoder.get_feature_names_out()\n",
        "\n",
        "# Join encoded dfs to a single df and show head\n",
        "all_cat_encoded_df = pd.concat([ord_encoded_df, bin_encoded_df, one_hot_encoded_df], axis=1)\n",
        "all_cat_encoded_df.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KXngFttG7Lzn"
      },
      "source": [
        "We can now join our encoded features back with the numerical features to give us our pre-processed data."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-s-_J01x7Lzn"
      },
      "outputs": [],
      "source": [
        "# Join numerical and categorical data\n",
        "X_train_cleaned = pd.concat([train_imputed_df[numerical_cols], all_cat_encoded_df], axis=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3HUDJHuy7Lzn"
      },
      "outputs": [],
      "source": [
        "# Check df\n",
        "X_train_cleaned.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yhpTTG6p7Lzn"
      },
      "source": [
        "Since we've used one-hot encoding for some of the features, we will almost certainly have issues with the 'dummy variable trap'. This occurs when one of the dummy variables is redudant, and introduces perfect multicollinearity. In simple terms, knowing the values of all feature values - 1 allows you to perfectly predict the last one. We can check the presence of multicolinearity using the variance inflation factor, or VIF:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GsDAkwwg7Lzn"
      },
      "outputs": [],
      "source": [
        "# Function to calculate VIF\n",
        "def calculate_vif(dataframe):\n",
        "    # Add a constant to the DataFrame (intercept term)\n",
        "    df_with_constant = add_constant(dataframe)\n",
        "\n",
        "    # Calculate VIF for each feature\n",
        "    vif_data = pd.DataFrame()\n",
        "    vif_data[\"Feature\"] = df_with_constant.columns\n",
        "    vif_data[\"VIF\"] = [variance_inflation_factor(df_with_constant.values, i)\n",
        "                       for i in range(df_with_constant.shape[1])]\n",
        "\n",
        "    return vif_data\n",
        "\n",
        "# Calculate VIF for encoded data\n",
        "vif_df = calculate_vif(X_train_cleaned)\n",
        "vif_df"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pZWSIi2l7Lzn"
      },
      "source": [
        "We can clearly see the features that were one-hot encoded (occupation and vehicle type) show perfect multicolinearity. The easiest way to deal with this is to drop one of the dummy variables from the encoded data. This is often referred to as dropping the 'reference category' or 'baseline' category."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7eaFeQBn7Lzn"
      },
      "outputs": [],
      "source": [
        "X_train_cleaned.drop(['occupation_Blue Collar' ,'vehicle_type_Minivan'], axis=1, inplace=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8cYG0wez7Lzn"
      },
      "source": [
        "We can now check VIF values again:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GUhMy4NU7Lzn"
      },
      "outputs": [],
      "source": [
        "# Calculate VIF for encoded data\n",
        "vif_df = calculate_vif(X_train_cleaned)\n",
        "vif_df"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_E8_uo2V7Lzn"
      },
      "source": [
        "### 5. Model Selection - Classfication\n",
        "We'll start by using several of the most popular classifiers with default parameters and compare how well they perform to indentify which might be best to proceed with."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ktzgeEHC7Lzo"
      },
      "outputs": [],
      "source": [
        "# Define the classifiers to test\n",
        "clfs = [\n",
        "    ('Logistic Regression', LogisticRegression(solver='liblinear', max_iter=2000)),\n",
        "    ('KNN', KNeighborsClassifier()),\n",
        "    ('Decision Tree', DecisionTreeClassifier()),\n",
        "    ('Random Forest', RandomForestClassifier(random_state=42)),\n",
        "    ('Linear SVM', LinearSVC(random_state=42, max_iter=1000, dual='auto')),\n",
        "    ('XGBoost', XGBClassifier(random_state=42)),\n",
        "    ('AdaBoost', AdaBoostClassifier(random_state=42, algorithm='SAMME')),\n",
        "    ('Gradient Boost', GradientBoostingClassifier(random_state=42)),\n",
        "    ('Bagging', BaggingClassifier(random_state=42)),\n",
        "    ('CatBoost', CatBoostClassifier(random_state=42, verbose=0)),\n",
        "]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "k9rlGNFk7Lzo"
      },
      "source": [
        "We'll use cross-validation to get a better understanding of each models performance, rather than just a single test. Let's create a KFold object so we can use the same folds for each classifier."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "h7Zk8RA87Lzo"
      },
      "outputs": [],
      "source": [
        "# Create KFold object with 10 folds\n",
        "kf = KFold(n_splits=10, shuffle=True, random_state=42)\n",
        "\n",
        "# Dictionary to store results\n",
        "results = {}\n",
        "\n",
        "# Evaluate each classifier using cross-validation\n",
        "for clf_name, clf in clfs:\n",
        "    cv_scores = cross_val_score(clf, X_train_cleaned, y_train, cv=kf)\n",
        "    results[clf_name] = cv_scores\n",
        "\n",
        "cv_scores_df = pd.DataFrame(results)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qqWWyDs97Lzo"
      },
      "source": [
        "Let's now plot the results of each test, for each classifyer with a boxplot so we can compare the models."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uAt8EoJ-7Lzo"
      },
      "outputs": [],
      "source": [
        "# Plot scores\n",
        "fig, ax = plt.subplots(figsize=(14, 8))\n",
        "sns.boxplot(cv_scores_df)\n",
        "\n",
        "# Add axis labels\n",
        "ax.set_xlabel('Classifier', fontsize=12)\n",
        "ax.set_ylabel('CV Accuracy Score', fontsize=12)\n",
        "ax.set_title('Cross-Validation Scores for Different Classifiers', fontsize=14)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fEPHbX2D7Lzo"
      },
      "source": [
        "From the table, we can see the best performing model was CatBoost, followed by Gradient Boost. The worst performing model was the Descision Tree.\n",
        "\n",
        "Although the CatBoost and Gradient Boost models performed better, I'll proceed for now with the XGBoost model, as hyperparameter tuning is much faster."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qGildwhv7Lzo"
      },
      "source": [
        "### 6. Feature Engineering\n",
        "Let's take a look at the distributions of our numerical features to see if we could potentially improve the performance of our models by transforming any existing features. First we'll create histograms for each of the numerical features."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JBJGvOss7Lzo"
      },
      "outputs": [],
      "source": [
        "# Melt the DataFrame to long format\n",
        "melted_X_train = X_train_cleaned[numerical_cols].melt(var_name='Column', value_name='Value')\n",
        "\n",
        "# Create a FacetGrid\n",
        "g = sns.FacetGrid(melted_X_train, col='Column', col_wrap=4, sharex=False, sharey=False, height=4)\n",
        "\n",
        "# Map the sns.histplot to each facet\n",
        "g.map(sns.histplot, 'Value', bins=25)\n",
        "\n",
        "# Add titles and labels\n",
        "g.set_axis_labels('Value', 'Frequency')\n",
        "g.set_titles(col_template='{col_name}')\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "akZ75KDb7Lzo"
      },
      "source": [
        "We can see that some of the features have a right skew. We can try to log transform these features to reduce the skew."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GgYxxYHY7Lzo"
      },
      "outputs": [],
      "source": [
        "# Define features we right skew\n",
        "skewed_features = ['income', 'value_of_home', 'commute_dist', 'vehicle_value', 'policy_tenure', 'license_points']\n",
        "\n",
        "# Define function to apply log transform\n",
        "def log_of_feature(data_df, skewed_features):\n",
        "    data = data_df.copy()\n",
        "    for feature in skewed_features:\n",
        "        data[feature] = np.sqrt(data[feature])\n",
        "    return data\n",
        "\n",
        "# Apply the function to X_train\n",
        "X_train_cleaned_log = log_of_feature(X_train_cleaned, skewed_features)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nVpsdplx7Lzo"
      },
      "source": [
        "We can now look at the distributions again to see if the log transform was effective at reducing the right skews."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xlEVqTIQ7Lzp"
      },
      "outputs": [],
      "source": [
        "melted_X_train = X_train_cleaned_log[numerical_cols].melt(var_name='Column', value_name='Value')\n",
        "g = sns.FacetGrid(melted_X_train, col='Column', col_wrap=4, sharex=False, sharey=False, height=4)\n",
        "g.map(sns.histplot, 'Value', bins=25)\n",
        "g.set_axis_labels('Value', 'Frequency')\n",
        "g.set_titles(col_template='{col_name}')\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sK2iQkgl7Lzp"
      },
      "source": [
        "The skews have been reduced, so let's now see if it has improved the performance of the XGBoost model."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "M7SAHC5b7Lzp"
      },
      "outputs": [],
      "source": [
        "xgb_boost_clf = XGBClassifier(random_state=42)\n",
        "\n",
        "cv_scores = cross_val_score(xgb_boost_clf, X_train_cleaned, y_train, cv=kf)\n",
        "cv_scores_log = cross_val_score(xgb_boost_clf, X_train_cleaned_log, y_train, cv=kf)\n",
        "\n",
        "print(f'CV score without log transform: {cv_scores.mean()}')\n",
        "print(f'CV score with log transform: {cv_scores_log.mean()}')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aUKtSk6d7Lzp"
      },
      "source": [
        "It's clear that our log transform made no impact in improving the base score. This is often to be expected with boosting models, as they are less sensitive to skew and scale than some models. However, it may be beneficial to our regression model later so we'll keep it."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "F6Gh5KiF7Lzp"
      },
      "source": [
        "#### Feature Scaling\n",
        "\n",
        "Now let's check if scaling our numerical features has any impact on model performance."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-YzsUhmi7Lzp"
      },
      "outputs": [],
      "source": [
        "# Define function to scale numeric features\n",
        "def scale_features(data_df, numeric_features):\n",
        "    data = data_df.copy()\n",
        "    # Initialise scaler\n",
        "    scaler = StandardScaler()\n",
        "    # Fit scaler to training data\n",
        "    scaler.fit(data[numeric_features])\n",
        "    # Transform numeric features\n",
        "    data[numeric_features] = scaler.transform(data[numeric_features])\n",
        "    return data\n",
        "\n",
        "# Apply the function to X_train\n",
        "X_train_cleaned_scaled = scale_features(X_train_cleaned_log, numerical_cols)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aMaXAEzi7Lzp"
      },
      "outputs": [],
      "source": [
        "xgb_boost_clf = XGBClassifier(random_state=42)\n",
        "\n",
        "cv_scores = cross_val_score(xgb_boost_clf, X_train_cleaned, y_train, cv=kf)\n",
        "cv_scores_scaled = cross_val_score(xgb_boost_clf, X_train_cleaned_scaled, y_train, cv=kf)\n",
        "\n",
        "print(f'CV score without log transform: {cv_scores.mean()}')\n",
        "print(f'CV score with log transform: {cv_scores_scaled.mean()}')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d2ydn5Z77Lzp"
      },
      "source": [
        "Again, it's clear that the scaling made no impact in improving the base score. However, it may be beneficial to our regression model later so we'll keep it."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dQDrYgLa7Lzp"
      },
      "outputs": [],
      "source": [
        "X_train_cleaned = X_train_cleaned_scaled.copy()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2sDpjzk87Lzp"
      },
      "source": [
        "### 7. Model Pipeline\n",
        "#### 7.1. Custom Transformers\n",
        "As we want to drop the unwanted 'red_vehicle' column, we'll create a custom transformer to do this that we can use in our pipeline."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_g9ohj2x7Lzp"
      },
      "outputs": [],
      "source": [
        "# Custom transformer to drop specified columns\n",
        "class ColumnDropper(BaseEstimator, TransformerMixin):\n",
        "    def __init__(self, columns_to_drop):\n",
        "        self.columns_to_drop = columns_to_drop\n",
        "\n",
        "    def fit(self, X, y=None):\n",
        "        return self\n",
        "\n",
        "    def transform(self, X):\n",
        "        return X.drop(columns=self.columns_to_drop)\n",
        "\n",
        "    def get_feature_names_out(self, input_features=None):\n",
        "        return None"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yw8rIh347Lzq"
      },
      "outputs": [],
      "source": [
        "class SqrtTransformer(BaseEstimator, TransformerMixin):\n",
        "    def __init__(self, columns_to_transform):\n",
        "        self.columns_to_transform = columns_to_transform\n",
        "\n",
        "    def fit(self, X, y=None):\n",
        "        return self\n",
        "\n",
        "    def transform(self, X):\n",
        "        X[self.columns_to_transform] = np.sqrt(X[self.columns_to_transform])\n",
        "        return X\n",
        "\n",
        "    def get_feature_names_out(self, input_features=None):\n",
        "        return input_features"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yW64k07c7Lzq"
      },
      "source": [
        "#### 7.2. Pipelines\n",
        "We can now define the pipelines for each of data/encoding types."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pd3gzIwA7Lzq"
      },
      "outputs": [],
      "source": [
        "from sklearn import set_config\n",
        "\n",
        "# Set transformer output to df so we can reference columns names\n",
        "set_config(transform_output='pandas')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "R8oa1Mz_7Lzq"
      },
      "outputs": [],
      "source": [
        "# Define column dropper pipeline\n",
        "cols_to_drop_pipeline = Pipeline([\n",
        "    ('col_dropper', ColumnDropper(cols_to_drop))\n",
        "])\n",
        "\n",
        "skewed_features = ['income', 'value_of_home', 'commute_dist', 'vehicle_value', 'policy_tenure', 'license_points']\n",
        "\n",
        "# Define numerical feature pipeline\n",
        "num_pipeline = Pipeline([\n",
        "    ('knn_imputer', KNNImputer(n_neighbors=2)),\n",
        "    ('sqrt', SqrtTransformer(skewed_features)),\n",
        "    ('scaler', StandardScaler()),\n",
        "])\n",
        "\n",
        "# Define rank of education levels\n",
        "education_rank = [['<High School', 'High School', 'Bachelors', 'Masters', 'PhD']]\n",
        "\n",
        "# Define ordinal categorical feature pipeline (highest_education feature)\n",
        "cat_ord_pipeline = Pipeline([\n",
        "    ('simple_imputer', SimpleImputer(strategy='most_frequent')),\n",
        "    ('ord_encoder', OrdinalEncoder(categories=education_rank)),\n",
        "])\n",
        "\n",
        "# Define binary categorical feature pipeline\n",
        "cat_bin_pipeline = Pipeline([\n",
        "    ('simple_imputer', SimpleImputer(strategy='most_frequent')),\n",
        "    ('binary_encoder', OrdinalEncoder()),\n",
        "])\n",
        "\n",
        "# Define one-hot categorical feature pipeline\n",
        "cat_one_hot_pipeline = Pipeline([\n",
        "    ('cat_simple_imputer', SimpleImputer(strategy='most_frequent')),\n",
        "    ('one_hot_encoder', OneHotEncoder(handle_unknown='ignore', sparse_output=False, drop='first')),\n",
        "])\n",
        "\n",
        "# Define preprocessing pipeline with a column transformer\n",
        "preprocess_pipeline = ColumnTransformer([\n",
        "    ('drop_features', cols_to_drop_pipeline, cols_to_drop),\n",
        "    ('num', num_pipeline, numerical_cols),\n",
        "    ('cat_ord', cat_ord_pipeline, cat_cols_ord),\n",
        "    ('cat_bin', cat_bin_pipeline, cat_cols_bin),\n",
        "    ('cat_one_hot', cat_one_hot_pipeline, cat_cols_one_hot),\n",
        "])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_BB-CZCq7Lzq"
      },
      "source": [
        "We can now transform the raw X_train dataset. With the pipeline."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cDN8o70w7Lzq"
      },
      "outputs": [],
      "source": [
        "X_train_prepared = preprocess_pipeline.fit_transform(X_train)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8s5Dkh-V7Lzq"
      },
      "source": [
        "We've transformed the test data using our pipeline. We can check the pipeline is correct by checking it against the DataFrame we built manually. We just need to make sure the column names match so we can compare them."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CnkDhj7Q7Lzq"
      },
      "outputs": [],
      "source": [
        "# Create df from processed data\n",
        "X_train_prepared_df = pd.DataFrame(\n",
        "    X_train_prepared,\n",
        "    columns=preprocess_pipeline.get_feature_names_out(),\n",
        ")\n",
        "\n",
        "# Get names of new one-hot columns\n",
        "one_hot_col_names = list(preprocess_pipeline.transformers_[4][1][1].get_feature_names_out(cat_cols_one_hot))\n",
        "\n",
        "# Create list of all columns names\n",
        "new_col_names = numerical_cols + cat_cols_ord + cat_cols_bin + one_hot_col_names\n",
        "\n",
        "# Rename df columns\n",
        "X_train_prepared_df.columns = new_col_names\n",
        "\n",
        "# Reset index\n",
        "X_train_prepared_df.reset_index(drop=True, inplace=True)\n",
        "\n",
        "# Inspect df\n",
        "X_train_prepared_df.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_5DRvqwu7Lzq"
      },
      "outputs": [],
      "source": [
        "# Inspect manually created df\n",
        "X_train_cleaned.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jzJbPVyF7Lzq"
      },
      "outputs": [],
      "source": [
        "X_train_cleaned.equals(X_train_prepared_df)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sXWWTN757Lzr"
      },
      "source": [
        "Great! We can see the output from the pipeline is the same as our manually created DataFrame."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GTr1c6Dk7Lzr"
      },
      "source": [
        "### 8. Hyperparamter Optimisation\n",
        "#### 8.1. Random Search\n",
        "To cover a larger parameter space, we'll first use RandomisedSearchCV with random values from a defined range. We can then focus in on a smaller range of values with GridSearchCV"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vt6sG-zf7Lzr"
      },
      "outputs": [],
      "source": [
        "# Define the parameter grid for XGBoost\n",
        "xgb_param_grid = {\n",
        "    'n_estimators': randint(low=50, high=300),\n",
        "    'learning_rate':uniform(0.01, 0.29),\n",
        "    'max_depth': randint(low=1, high = 20),\n",
        "    'subsample': uniform(0, 1),\n",
        "    'colsample_bytree': uniform(0, 1),\n",
        "    'min_child_weight': randint(low=1, high= 20),\n",
        "    'reg_alpha': randint(low=0, high=100),\n",
        "    'reg_lambda':randint(low=0, high=10),\n",
        "    'gamma': uniform(0, 1),\n",
        "}\n",
        "\n",
        "# Initialize the XGBClassifier\n",
        "xgb_model = XGBClassifier(random_state=42, eval_metric='error')\n",
        "\n",
        "# Set up RandomizedSearchCV with F1 score as the evaluation metric\n",
        "scorer = make_scorer(f1_score, average='weighted')\n",
        "random_search = RandomizedSearchCV(\n",
        "    estimator=xgb_model,\n",
        "    param_distributions=xgb_param_grid,\n",
        "    n_iter=2000,  # Increased number of iterations\n",
        "    scoring=scorer,\n",
        "    cv=5,\n",
        "    verbose=1,\n",
        "    random_state=42,\n",
        "    n_jobs=-1\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XUWAw_YS7Lzr"
      },
      "outputs": [],
      "source": [
        "# Fit the model using RandomizedSearchCV\n",
        "random_search.fit(X_train_prepared, y_train)\n",
        "\n",
        "# Print the best parameters and the best score\n",
        "print(\"Best parameters found: \", random_search.best_params_)\n",
        "print(\"Best cross-validation score: \", random_search.best_score_)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wVEndp-X7Lzr"
      },
      "source": [
        "#### 8.2. Grid Search\n",
        "OK, we now have the best parameter values from our Random Search. As we've reduce the parameter space, we can now use grid search to check parameter combinations within the reduced grid space."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zdjZrv4j7Lzr"
      },
      "outputs": [],
      "source": [
        "# Define the parameter grid with expanded ranges\n",
        "xgb_param_grid_grid_search = {\n",
        "    'n_estimators': [280, 290, 300],\n",
        "    'max_depth': [6, 7, 8],\n",
        "    'learning_rate': [0.03, 0.04, 0.05],\n",
        "    'subsample': [0.45, 0.5, 0.55],\n",
        "    'colsample_bytree': [0.5, 0.55, 0.6],\n",
        "    'gamma': [0.05, 0.1, 0.15],\n",
        "    'min_child_weight': [18],\n",
        "    'reg_alpha': [1],\n",
        "    'reg_lambda': [1],\n",
        "}\n",
        "\n",
        "# Initialize the XGBClassifier\n",
        "xgb_model = XGBClassifier(random_state=42, eval_metric='error')\n",
        "\n",
        "# Set up RandomizedSearchCV with F1 score as the evaluation metric\n",
        "scorer = make_scorer(f1_score, average='weighted')\n",
        "grid_search = GridSearchCV(\n",
        "    estimator=xgb_model,\n",
        "    param_grid=xgb_param_grid_grid_search,\n",
        "    scoring=scorer,\n",
        "    cv=5,\n",
        "    verbose=1,\n",
        "    n_jobs=-1\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8cEGkDra7Lzr"
      },
      "outputs": [],
      "source": [
        "# Fit the model using RandomizedSearchCV\n",
        "grid_search.fit(X_train_prepared, y_train)\n",
        "\n",
        "# Print the best parameters and the best score\n",
        "print(\"Best parameters found: \", grid_search.best_params_)\n",
        "print(\"Best cross-validation score: \", grid_search.best_score_)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UTadOLGa7Lzr"
      },
      "source": [
        "We've now got the result from the grid search. Let's compared the model scores for the default model, and the tuned model:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jfW37wsZ7Lzr"
      },
      "outputs": [],
      "source": [
        "print(f'XGBoost model score (default hyperparameters): {cv_scores.mean()}')\n",
        "print(f'XGBoost model score (tuned hyperparamters: {grid_search.best_score_}')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mlUUfefZ7Lzr"
      },
      "source": [
        "Great, we saw an improvement of nearly 0.8%."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lBqjrjt87Lzs"
      },
      "source": [
        "### 9. Model Evaluation\n",
        "It's now time to test the model with our test set."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GQ6WKAUw7Lzs"
      },
      "outputs": [],
      "source": [
        "# Prepare test set using pipeline\n",
        "X_test_prepared = preprocess_pipeline.fit_transform(X_test)\n",
        "\n",
        "# Predict the y_test values using the best model from the grid search\n",
        "y_pred = grid_search.best_estimator_.predict(X_test_prepared)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Wkx-YDLb7Lzs"
      },
      "source": [
        "We can now check the f1 score of our test set predictions:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CN8aj9NY7Lzs"
      },
      "outputs": [],
      "source": [
        "f1_score(y_test, y_pred, average='weighted')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sOOWdPgb7Lzs"
      },
      "source": [
        "Let's create a confusion matrix for our model with the results of the test set to better understand it's performance."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6YSKEfvs7Lzs"
      },
      "outputs": [],
      "source": [
        "# Compute the confusion matrix\n",
        "cm = confusion_matrix(y_test, y_pred)\n",
        "\n",
        "# Display the confusion matrix using ConfusionMatrixDisplay\n",
        "disp = ConfusionMatrixDisplay(confusion_matrix=cm)\n",
        "disp.plot()\n",
        "plt.title('Confusion Matrix on Training Data')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WTlmgQPv7Lzs"
      },
      "source": [
        "### 10.Regression\n",
        "#### 10.1 Train/Test Sets\n",
        "\n",
        "We can now look at the regression part of this project. We want to predict the total value of a claim, assuming a claim has been made. We start by creating the test/train sets, using only records where the claim value > 0."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oerBwUWa7Lzs"
      },
      "outputs": [],
      "source": [
        "# Filter to only rows with a non-zero claim value\n",
        "claim_data = data_df[data_df['new_claim_value'] > 0]\n",
        "\n",
        "# Create clean copy of training data\n",
        "X_reg = claim_data.copy()\n",
        "y_reg = claim_data['new_claim_value']\n",
        "\n",
        "# Drop the target feature\n",
        "X_reg.drop(columns=['new_claim_value','is_claim', 'claim_value_cat'], inplace=True)\n",
        "\n",
        "# Create train/test split\n",
        "X_reg_train, X_reg_test, y_reg_train, y_reg_test = train_test_split(X_reg, y_reg, test_size=0.2, random_state=42)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uF0fchLC7Lzt"
      },
      "source": [
        "We can now use the pipeline to preprocess our train set."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mWbQbL8B7Lzt"
      },
      "outputs": [],
      "source": [
        "# Use the same pipeline as the classifier model to preprocess X train\n",
        "X_reg_train_prepared = preprocess_pipeline.fit_transform(X_reg_train)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Lyk28-6Y7Lzt"
      },
      "source": [
        "#### 10.2. Model Selection\n",
        "We'll start by looking at the performance of some of the most popular regression models."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "a3UxvflL7Lzt"
      },
      "outputs": [],
      "source": [
        "regs = [\n",
        "    ('Linear Regression', LinearRegression()),\n",
        "    ('Logistic Regression', LogisticRegression(random_state=42, max_iter=25, solver='sag', tol=3)),\n",
        "    ('SGD Regressor', SGDRegressor(random_state=42)),\n",
        "    ('Decision Tree Regression ', DecisionTreeRegressor(random_state=42)),\n",
        "    ('Random Forest', RandomForestRegressor(random_state=42)),\n",
        "    ('KNN Model ', KNeighborsRegressor()),\n",
        "    ('Support Vector Machines (SVM)', SVR(gamma=2, C=1)),\n",
        "    ('XGBRegressor', XGBRegressor(random_state=42))\n",
        "]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UGwROCJ97Lzt"
      },
      "source": [
        "Like with the classification models, we'll use a KFold object to use the same folds for the cross-validation of each model.\n",
        "\n",
        "For the scoring of the model, we'll use the RMSE as it's more sensitive to outliers."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wnrmtobt7Lzt"
      },
      "outputs": [],
      "source": [
        "# Create KFold object with 10 folds\n",
        "reg_kf = KFold(n_splits=10, shuffle=True, random_state=42)\n",
        "\n",
        "# Dictionary to store results\n",
        "reg_results = {}\n",
        "\n",
        "# Evaluate each classifier using cross-validation\n",
        "for reg_name, reg in regs:\n",
        "    cv_rmses = -cross_val_score(reg, X_reg_train_prepared, y_reg_train, cv=reg_kf, scoring='neg_root_mean_squared_error')\n",
        "    reg_results[reg_name] = cv_rmses\n",
        "\n",
        "reg_cv_scores_df = pd.DataFrame(reg_results)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "prVZbFN27Lzt"
      },
      "source": [
        "And again, let's create a boxplot of the results of the cross-validation for each model."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2vQY0pZc7Lzt"
      },
      "outputs": [],
      "source": [
        "# Plot scores\n",
        "fig, ax = plt.subplots(figsize=(16, 8))\n",
        "sns.boxplot(reg_cv_scores_df)\n",
        "\n",
        "# Add axis labels\n",
        "ax.set_xlabel('Regressor', fontsize=12)\n",
        "ax.set_ylabel('CV RMSE', fontsize=12)\n",
        "ax.set_title('Cross-Validation Scores for Different Regressors', fontsize=14)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CZpIKjvm7Lzt"
      },
      "source": [
        "As we're using the RMSE as the scoring method, lower is better. We can see the linear regression and SGD Regressor models performed the best. Their scores were very similar, as the models themselves are. As we have more flexibility to tune the SGD Regressor, we'll proceed with that."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "inRFl1Wz7Lzt"
      },
      "source": [
        "#### 10.3. Hyperparameter Optimisation\n",
        "As we did with the classification model, we'll first use random search to cover a large parameter space."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-Lb9VNev7Lzt"
      },
      "outputs": [],
      "source": [
        "# Define the parameter grid for SGDRegressor\n",
        "reg_param_grid = {\n",
        "    'penalty': ['l2', 'l1', 'elasticnet'],\n",
        "    'alpha': uniform(0.0001, 0.01),\n",
        "    'learning_rate': ['constant', 'invscaling'],\n",
        "    'eta0': uniform(0.001, 0.1),\n",
        "    'max_iter': randint(100, 1000),\n",
        "    'tol': uniform(1e-6, 1e-3)\n",
        "}\n",
        "\n",
        "# Initialise the regressor\n",
        "sgd_regressor = SGDRegressor(random_state=42)\n",
        "\n",
        "# Create random search\n",
        "reg_random_search = RandomizedSearchCV(\n",
        "    estimator=sgd_regressor,\n",
        "    param_distributions=reg_param_grid,\n",
        "    n_iter=500,\n",
        "    scoring='neg_mean_squared_error',\n",
        "    cv=reg_kf,\n",
        "    verbose=1,\n",
        "    random_state=42,\n",
        "    n_jobs=-1\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jhatNkej7Lzu"
      },
      "outputs": [],
      "source": [
        "# Fit the model using RandomizedSearchCV\n",
        "random_search.fit(X_reg_train_prepared, y_reg_train)\n",
        "\n",
        "score = np.sqrt(-random_search.best_score_)\n",
        "\n",
        "# Print the best parameters and the best score\n",
        "print(\"Best parameters found: \", random_search.best_params_)\n",
        "print(\"Best cross-validation score: \", score)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9hC-xgJV7Lzu"
      },
      "source": [
        "We can now use grid search with the reduce parameter space."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "L2-qr_O97Lzu"
      },
      "outputs": [],
      "source": [
        "# Define the parameter grid for SGDRegressor\n",
        "reg_param_grid_gs = {\n",
        "    'penalty': ['l2', 'l1', 'elasticnet'],\n",
        "    'alpha': [0.004, 0.008, 0.012],\n",
        "    'learning_rate': ['invscaling'],\n",
        "    'eta0': [0.001, 0.003, 0.005],\n",
        "    'max_iter': [180, 200, 220],\n",
        "    'tol': [1e-5, 1e-4, 1e-6]\n",
        "}\n",
        "\n",
        "# Initialise the regressor\n",
        "sgd_regressor = SGDRegressor(random_state=42)\n",
        "\n",
        "# Create random search\n",
        "reg_grid_search = GridSearchCV(\n",
        "    estimator=sgd_regressor,\n",
        "    param_grid=reg_param_grid_gs,\n",
        "    scoring='neg_mean_squared_error',\n",
        "    cv=reg_kf,\n",
        "    verbose=1,\n",
        "    n_jobs=-1\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3K1-ZQmN7Lzu"
      },
      "source": [
        "Let's now fit the grid search, and return the best parameter values and best score."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DfbFcS3X7Lzu"
      },
      "outputs": [],
      "source": [
        "# Fit the model\n",
        "reg_grid_search.fit(X_reg_train_prepared, y_reg_train)\n",
        "\n",
        "reg_score = np.sqrt(-reg_grid_search.best_score_)\n",
        "\n",
        "# Print the best parameters and the best score\n",
        "print(\"Best parameters found: \", reg_grid_search.best_params_)\n",
        "print(\"Best cross-validation score: \", reg_score)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8032E0Qd7Lzu"
      },
      "source": [
        "We've only managed to improve the model score very slightly, but an improvement nonetheless."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4LY2GWHq7Lzu"
      },
      "source": [
        "#### 10.4. Model Evaluation\n",
        "We can now test our regression model with the test sets to see our final score."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "U1-d0Hap7Lzu"
      },
      "outputs": [],
      "source": [
        "X_reg_test_prepared = preprocess_pipeline.fit_transform(X_reg_test)\n",
        "\n",
        "y_reg_pred = reg_grid_search.best_estimator_.predict(X_reg_test_prepared)\n",
        "\n",
        "mse = mean_squared_error(y_reg_test, y_reg_pred)\n",
        "rmse = np.sqrt(mse)\n",
        "\n",
        "mae = mean_absolute_error(y_reg_test, y_reg_pred)\n",
        "\n",
        "print(f'RMSE: {rmse}')\n",
        "print(f'MAE: {mae}')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "j2nBLkxH7Lzu"
      },
      "source": [
        "We can see the RMSE score was slightly higher than what we saw in the train sets, but still fairly inline. As with the classification model, there is still lots of room for potential improvement, like additional feature engineering, investigating feature importance or combining multiple models to create an ensemble."
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.2"
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}